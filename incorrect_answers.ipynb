{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/KristiyanVachev/Question-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import fr_core_news_sm\n",
    "from dateutil.parser import parse\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "telechargement : https://github.com/KristiyanVachev/Question-Generation/tree/master/data/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "telechargement : https://fauconnier.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRANCAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_fr = fr_core_news_sm.load()\n",
    "french_model = KeyedVectors.load_word2vec_format(\"data/frWac_no_postag_no_phrase_700_skip_cut50.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def modify_date(answer_date):\n",
    "    int_confidence_year = 3\n",
    "    sooner_random_answer_tuple = (answer_date.year - int_confidence, answer_date.month - random.randint(0, answer_date.month), answer_date.day - random.randint(0, answer_date.day))\n",
    "    new_answer_year = answer_date.year - random.randint(0, int_confidence_year)\n",
    "    new_answer_month = answer_date.month - random.randint(0, answer_date.month - 1)\n",
    "    new_answer_day = answer_date.day - random.randint(0, answer_date.day - 1)\n",
    "    return datetime.datetime(new_answer_year, new_answer_month, new_answer_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_tags = [\"ADV_\", \"ADP_\", \"VERB\", \"PRON\"]\n",
    "def modify_answer(answer, nlp_fr, model_fr):\n",
    "    answer = answer.lower()\n",
    "    doc_fr = nlp_fr(answer)\n",
    "    important_words_answer = [X for X in doc_fr if X.tag_[:4] not in avoid_tags] # 4 == taille des avoid_tags\n",
    "    for important_word_answer in important_words_answer:\n",
    "        try:\n",
    "            if is_date(important_word_answer.text):\n",
    "                answer_date = parse(important_word_answer.text)\n",
    "                new_date = modify_date(answer_date)\n",
    "                answer = answer.replace(important_word_answer.text, str(new_date))\n",
    "            else:\n",
    "                similar_words = french_model.most_similar(important_word_answer.text)\n",
    "                random_position_answer = random.randint(0, len(similar_words) - 1)\n",
    "                other_answer = similar_words[random_position_answer][0] \n",
    "                answer = answer.replace(important_word_answer.text, other_answer)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[marseille, ,, midi, ,, .]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'à mazargues, à petitdéjeuner, nous mangerons.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"à Marseille, à midi, nous mangerons.\"\n",
    "modify_answer(s, nlp_fr, french_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
